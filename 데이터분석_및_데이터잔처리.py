# -*- coding: utf-8 -*-
"""데이터분석 및 데이터잔처리.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sRNctKopPaNNiAf7AhZxjnF7YFqashb6
"""

from google.colab import drive   #코랩과 연동하기 위함

drive.mount('/content/gdrive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/gdrive/MyDrive/Colab Notebooks/code2024/Session05 - 데이터 분석 및 데이터 전처리

import numpy as np

import pandas as pd

csData = pd.read_csv('../dataset/customerdata.csv')

csData.head(2)

emiCondition =2
deviceCondition =3
csData.loc[(csData.EMI == 2)&
(csData.DEVICECOUNT>3)]

csData.dtypes

###프로젝트 실습

selloutData = pd.read_csv('../dataset/kopo_channel_seasonality_new.csv')

selloutData

selloutData.YEARWEEK.astype(str)

selloutData.REGIONID.astype(str)

selloutData.PRODUCT.astype(str)

selloutData.QTY.astype(str)

selloutData.dtypes

selloutData.iloc[:,[1,2]]

customerData= pd.read_csv("../dataset/customerdata.csv")

targetColumns = ["CUSTID","DEVICECOUNT"]  #컬럼 이름으로 쓰는 추세이다. 같이 협업할때 불편하기때문
csData.loc[:,{"CUSTID","DEVICECOUNT"}]
csData.iloc[:,[0,3]]

csDataIndex = csData.loc[csData.EMI ==3].reset_index() ## 데이터 0부터 다시 초기화 정렬할때 많이 사용 .reset_index(drop=True) 이렇게 해도됨
csDataIndex

csData["PRODUCTAGE_NEW"] =1
csData["PRODUCTAGE_NEW"] =np.where(csData.PRODUCTAGE < 1,1,0)

csData

csData.loc[(csData.PRODUCTAGE <1)&(csData.PRODUCTAGE_NEW !=1)]

csData["PRODUCTAGE_NEW"] =np.where(csData.PRODUCTAGE <1 ,1,
         np.where (csData.PRODUCTAGE <2,2,3))
csData

def productAgeFilter(inProductAge):
    #inProductAge=2

    outProductAge= 0
    if inProductAge < 1:
        outProductAge =1
    elif inProductAge<2:
        outProductAge =2
    else:
        outProductAge =3

    return outProductAge

csData["PRODUCTAGE_NEW"] = csData.PRODUCTAGE.apply(productAgeFilter)

def trimmedAvg (inList):

   # inList = [100,120,130,150,170]
    minValue = min(inList)
    maxValue = max (inList)
    inList.remove(minValue)
    inList.remove(maxValue)
    #평균구하기
    trimmedMean = sum(inList)/len(inList)
    return trimmedMean

trimmedAvg([1,2,3,4,5])  #최대, 최솟값 제외한 나머지값의 평균

csData.CUSTID * csData.DEVICECOUNT   #문자 x 숫자 =그 문자 반복

csData["NEW_COL"] =csData.EMI.astype(int) * csData.DEVICECOUNT.astype(int)

csData

csData.CUSTID.str[0:1]+"_"+csData.EMI.astype(str)

#[불량 데이터 처리]
#kopo_channel_seasonality_new.csv 자료를 담은
#selloutData 변수에서
#QTY컬럼 음수(반품)인 경우 0, 양수인 경우 기존 QTY 값
#유지하는 로직을 적용하여 QTY_NEW 컬럼을 추가하세요

selloutData["QTY_NEW"] =np.where(selloutData.QTY<0 , 0
                                 , selloutData.QTY)

selloutData.QTY.max()
selloutData.QTY.min()
selloutData.QTY.sum()
selloutData.QTY.count()
selloutData[selloutData.QTY < 0]["QTY"].count()

selloutData.loc [ (selloutData.QTY>=0) & (selloutData.QTY_NEW)]

"""#주차정보생성 및 53주차 제거

"""

yearindex =4

selloutData["YEAR"] = selloutData.YEARWEEK.astype(str).str[0:4]
selloutData["WEEK"] = selloutData.YEARWEEK.astype(str).str[4:]
refinedSelloutData = selloutData.loc[selloutData.WEEK != "53"]
refinedSelloutData = refinedSelloutData.loc[refinedSelloutData.WEEK.astype(int) < 53]

refinedSelloutData

"""#데이터 정렬"""

csData = pd.read_csv("../dataset/customerdata.csv")
sortkey = ["EMI","AVGPRICE"]
csData.sort_values(sortkey)  #오름차순으로 정렬  ,ascending(False) #내림차순

"""#데이터 그룹별 집계함수 구현"""

csData = pd.read_csv("../dataset/customerdata.csv")
groupkey = ["EMI"]
csData.groupby(groupkey)["AVGPRICE"].agg(["mean"])

csData = pd.read_csv("../dataset/customerdata.csv")
groupkey = ["EMI"]
csData.groupby(groupkey)["AVGPRICE"].agg(["mean","min","std","max"])

csData = pd.read_csv("../dataset/customerdata.csv")
groupkey = ["EMI"]
grouptData= csData.groupby(groupkey)["AVGPRICE"].agg(["mean"]).reset_index()
grouptData= csData.rename (columns = {"mean":"AVGPRICE_MEAN"})
grouptData

refinedSelloutData

groupKey = ["REGIONID", "PRODUCT", "YEAR"]

refinedSelloutData.groupby(groupKey)["QTY"].agg(["mean"]).reset_index

"""#프로젝트실습
[지역, 상품, 연도 별 집계]
 sortedData 에서 지역, 상품, 연도 단위
판매량(QTY_NEW) 의 평균 연산 후
groupData 변수에 담으세요
이후 컬럼명을 QTY_MEAN로 변경하세요
"""

groupKey = ["REGIONID","PRODUCT","YEAR"]

groupData = sortedData.groupby(groupKey, as_index=False).QTY_NEW.mean()

groupData = groupData.rename(columns = {'QTY_NEW': 'QTY_MEAN'})

groupData.head()

"""#이동평균 산출"""

maData = pd.read_csv("../dataset/kopo_product_volume.csv" )
sortKey = ["REGIONID","PRODUCTGROUP","YEARWEEK"]
maData.VOLUME.rolling(window=5, center = True, min_periods=3).mean()
maData

maData = pd.read_csv("../dataset/kopo_product_volume.csv" )
sortKey = ["REGIONID","PRODUCTGROUP","YEARWEEK"]
maData  = maData.sort_values(sortKey)
maData['MA5'] = maData.VOLUME.rolling(window=5, center = True, min_periods=3).mean()
maData

"""#데이터 설명
join_region_master.csv,
 join_kopo_product_volume.csv
 joinMaster, joinSellout 변수에 담으세요
"""

joinMaster= pd.read_csv("../dataset/join_region_master.csv",encoding="ms949")  #한글일경우 오류뜸 99프로는 이걸로 해결됨
joinSellout= pd.read_csv("../dataset/join_kopo_product_volume.csv")
pd.merge(left = joinSellout,
         right= joinMaster,
         left_on= ["REGIONID"],
         right_on= ["REGIONID"] )

targetRegion = ["A01","A03"]

joinMaster3= joinMaster.loc[joinMaster. REGIONID =='A01']
joinMaster3

# innerjoin, leftjoin(데이터분석) 면접질문 아무도 대답 못함

#left join 기준이되는 왼쪽은 무조건 살린다

"""#프로젝트 실습

join_region_master.csv,
 join_kopo_product_volume.csv
 joinMaster, joinSellout 변수에 담으세요
"""

HKCODE